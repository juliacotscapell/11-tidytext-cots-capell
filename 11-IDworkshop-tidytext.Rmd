---
title: "11-IDworkshop-tidytext"
author: "Cots_Ruzelyte"
date: "`r format(Sys.time(), '%B %d, %Y | %H:%M:%S | %Z')`"
output:
  html_document:
    code_folding: show
    df_print: paged
    highlight: tango
    number_sections: no
    theme: cosmo
    toc: no
---
  
<style>
div.answer {background-color:#f3f0ff; border-radius: 5px; padding: 20px;}
</style>

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      eval = TRUE,
                      error = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      comment = NA)
```

```{r, include = T}
library(rvest)
library(stringr)
library(tidyverse)
library(tidytext)
library(wordcloud2)
```

<br>

#### üëã **WELCOME TO THE WORKSHOP #11 ON THE PACKAGE TIDYTEXT**

For this purpose, we're going to , consists of the two speeches: 

- President Obama's Inaugural Address; 20th January 2009. 

- President Trump's Inaugural Address; 20th January 2017. 


<br>

#### üë©üíª **STEP 0. Data scraping and preparation.**

In order to obtain the inauguration speeches that we're interested in analysing, we scraped the websites with the transcripsts of the speeches. For the purpose of this workshop, and in the interest of time, we provide you with the code to obtain the text. Each president's speech is stored in a string named "*_text". 

```{r}
#OBAMA
obama_link <- read_html("http://obamaspeeches.com/P-Obama-Inaugural-Speech-Inauguration.htm")
obama_text <- html_text(html_elements(obama_link, xpath = "//td/font[@size='3']")) 

#TRUMP
trump_link <- read_html("https://www.politico.com/story/2017/01/full-text-donald-trump-inauguration-speech-transcript-233907")
trump_text <- html_text(html_elements(trump_link, xpath = "//div[@class='story-text']/p"))
trump_text <- trump_text[c(2:14)]

```


We will now convert the strings into dataframes for better manipulation in the future steps and in order to be able to apply the tidytext package functions which require a tidy-data structure.

``` {r}
obama_speech_df <- tibble(Text=obama_text)
trump_speech_df <- tibble(Text=trump_text)

```

We can see that each speech is stored as rows of the dataframe, with the whole text stored in **one column**. However, because of the formatting of every website from which we obtained the transcript, Obama's speech is stored as one single row, whereas Trump's speech is split in paragraphs. Nevertheless, our future analysis won't be affected by this circumstance, given that our unit of interest will be words. 

<br>

#### üßπüßº **STEP 1. Clean the data (tidy data).**

XXXXXXXX

````{r}

##We create new dataframes in which each line is a word
obama_words <- obama_speech_df %>% 
  unnest_tokens(output=word, input=Text)

trump_words <- trump_speech_df %>% 
  unnest_tokens(output=word, input=Text)

#We add a new column in each called president to be able to group words by this category later. 
obama_words <- obama_words %>% 
  mutate(president = "obama")

trump_words <- trump_words %>% 
  mutate(president = "trump")

#We merge them to be able to work with one single dataframe
together_words <- bind_rows(obama_words, trump_words)

#Remove stopwords
together_clean <- together_words %>% 
  anti_join(stop_words)


````

<br>

#### üóØüì£ **STEP 2. Word analysis.**

````{r}
#We want to know the 8-most-common used words by each of the presidents in their inauguration speeches
together_clean %>% 
  group_by(president) %>% 
  count(word) %>% 
  top_n(8)


#We create a table that allows us to see the number of times each word is said by president (in the same line)
comparison <- together_clean %>% 
  count(word, president) %>% 
  group_by(word) %>% 
  filter(n >=4) %>%  #we saw that the top 10 most-used words they were used at least 4 times
  ungroup(word) %>% 
  pivot_wider(
    names_from = president, 
    values_from = n, 
    names_prefix = "president_", 
    values_fill = 0
  )

#Ratios
comparison %>% 
  mutate(
    obama_ratio = round(100*((president_obama) / (sum(president_obama))),2),
    trump_ratio = round(100*((president_trump) / (sum(president_trump))),2)
  )


````



````{r}
#Usage of word "I"

times_I <- together_words %>% #use initial dataframe with stopwords (bc I is considered a stopword)
  group_by(president) %>% 
  count(word == "i") %>% 
  mutate(share_I = 100*(n/sum(n))) %>%  #figure out how to round this
  select(!n) %>% 
  pivot_wider(
    names_from = president, 
    values_from = share_I, 
    names_prefix = "president_", 
  ) 

#Usage of word "we"
times_we <- together_words %>% #use initial dataframe with stopwords (bc I is considered a stopword)
  group_by(president) %>% 
  count(word == "we") %>% 
  mutate(share_we = 100*(n/sum(n))) %>%  #figure out how to round this
  select(!n) %>% 
  pivot_wider(
    names_from = president, 
    values_from = share_we, 
    names_prefix = "president_", 
  ) 

#COMPARE BOTH WORDS TOGETHER IN ONE DATAFRAME
I_we_comparison <- bind_rows(times_I, times_we)

I_we_share <- I_we_comparison %>% 
  select(president_obama, president_trump) %>% 
  mutate(across(1:2, round,3))

I_we_share <- I_we_share[c(2,4),]

#We add a column to know what word it is
personal_word <- c("I", "we")
word_type <- data.frame(personal_word)
I_we_share %>% 
  bind_cols(word_type)


````

<br>

#### üòç/üò¢ **STEP 3. Sentiment analysis.**

````{r}
#Analysis of the general sentiment of the speeches

sentiments <- get_sentiments("bing") #we load the bing-sentiments lexicon

word_sentiments <- inner_join(together_words, sentiments) #we merge the sentiment column to add a validation of the sentiment behind each word

#we calculate the share of positive / negative words used by each president in all the speech
sentiments_analysis <- word_sentiments %>% 
  group_by(president) %>% 
  count(president, sentiment) %>% 
  mutate(share = round(n/sum(n),2))


sentiments_analysis %>%
  select(!n) %>% 
  pivot_wider(
    names_from = sentiment,
    values_from = share
  )


````

<br>

#### üìä **STEP 4. Plot the results.** 

Let's do it cooler. We now want to plot most-used words in wordclouds. 

```{r pressure, echo=FALSE}

obama_wordcloud <- together_clean %>% 
  filter(president=="obama") %>% 
  count(word, sort=T) %>% 
  head(50) %>% 
  wordcloud2(size= .4,
            color = c("darkblue", "red", "darkgreen"))
obama_wordcloud


```

````{r}
trump_wordcloud <- together_clean %>% 
  filter(president=="trump") %>% 
  count(word, sort=T) %>% 
  head(50) %>% 
  wordcloud2(size= .4,
            color = c("darkblue", "red", "darkgreen"))
trump_wordcloud

````

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
